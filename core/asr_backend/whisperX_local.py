import os
import subprocess
import whisperx
import torch
from pathlib import Path

def check_hf_mirror():
    """
    ç´§æ€¥ä¿®å¤ç‰ˆæœ¬ï¼šç›´æ¥è¿”å›HuggingFaceå®˜æ–¹åœ°å€
    è§£å†³Railwayç¯å¢ƒä¸­pingå‘½ä»¤ä¸å­˜åœ¨çš„é—®é¢˜
    """
    # ç›´æ¥è¿”å›å®˜æ–¹åœ°å€ï¼Œè·³è¿‡æ‰€æœ‰ç½‘ç»œæ£€æµ‹
    hf_endpoint = "https://huggingface.co"
    print(f"âœ… ä½¿ç”¨HuggingFaceå®˜æ–¹ç«¯ç‚¹: {hf_endpoint}")
    print("ğŸ”§ å·²è·³è¿‡pingæ£€æµ‹ï¼Œé¿å…å®¹å™¨ç¯å¢ƒé”™è¯¯")
    return hf_endpoint

def transcribe_audio(audio_file, vocal_file, start_time=None, end_time=None):
    """
    ä½¿ç”¨WhisperXè¿›è¡ŒéŸ³é¢‘è½¬å½•
    """
    try:
        # è®¾ç½®HuggingFaceç«¯ç‚¹
        os.environ['HF_ENDPOINT'] = check_hf_mirror()
        
        # æ£€æŸ¥CUDAå¯ç”¨æ€§
        device = "cuda" if torch.cuda.is_available() else "cpu"
        compute_type = "float16" if device == "cuda" else "int8"
        
        print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
        print(f"ğŸ”§ è®¡ç®—ç±»å‹: {compute_type}")
        
        # åŠ è½½Whisperæ¨¡å‹
        model = whisperx.load_model("large-v2", device, compute_type=compute_type)
        
        # åŠ è½½éŸ³é¢‘
        audio = whisperx.load_audio(vocal_file)
        
        # å¦‚æœæŒ‡å®šäº†æ—¶é—´æ®µï¼Œè£å‰ªéŸ³é¢‘
        if start_time is not None and end_time is not None:
            sample_rate = 16000  # WhisperXé»˜è®¤é‡‡æ ·ç‡
            start_sample = int(start_time * sample_rate)
            end_sample = int(end_time * sample_rate)
            audio = audio[start_sample:end_sample]
        
        # è½¬å½•éŸ³é¢‘
        print("ğŸ¤ å¼€å§‹éŸ³é¢‘è½¬å½•...")
        result = model.transcribe(audio, batch_size=16)
        
        # åŠ è½½å¯¹é½æ¨¡å‹
        print("ğŸ”„ åŠ è½½å¯¹é½æ¨¡å‹...")
        model_a, metadata = whisperx.load_align_model(
            language_code=result["language"], 
            device=device
        )
        
        # å¯¹é½è½¬å½•ç»“æœ
        print("ğŸ“ å¯¹é½è½¬å½•ç»“æœ...")
        result = whisperx.align(
            result["segments"], 
            model_a, 
            metadata, 
            audio, 
            device, 
            return_char_alignments=False
        )
        
        print("âœ… éŸ³é¢‘è½¬å½•å®Œæˆ")
        return result
        
    except Exception as e:
        print(f"âŒ è½¬å½•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        raise e

def get_whisper_result():
    """
    è·å–Whisperè½¬å½•ç»“æœçš„ä¸»å‡½æ•°
    """
    try:
        # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„è¿›è¡Œè°ƒç”¨
        # ç¤ºä¾‹è°ƒç”¨ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦ä¼ å…¥æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„ï¼‰
        # result = transcribe_audio("input.wav", "vocal.wav")
        # return result
        pass
    except Exception as e:
        print(f"âŒ è·å–è½¬å½•ç»“æœå¤±è´¥: {str(e)}")
        raise e

# å…¼å®¹æ€§å‡½æ•°
def ensure_hf_endpoint():
    """
    ç¡®ä¿HuggingFaceç«¯ç‚¹å·²è®¾ç½®
    """
    if 'HF_ENDPOINT' not in os.environ:
        os.environ['HF_ENDPOINT'] = check_hf_mirror()
    return os.environ['HF_ENDPOINT']

# åˆå§‹åŒ–æ—¶è‡ªåŠ¨è®¾ç½®ç«¯ç‚¹
ensure_hf_endpoint()

print("ğŸš€ WhisperXæœ¬åœ°æ¨¡å—å·²åŠ è½½ï¼ˆä¿®å¤ç‰ˆï¼‰")
print("âœ… å·²è§£å†³pingå‘½ä»¤é”™è¯¯é—®é¢˜")

